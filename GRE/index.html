<!DOCTYPE html>
<head>
<meta charset="utf-8" />
<title>Graph Runtime Engine</title>
<meta name="description" content="This is home of GRE.">
<meta name="keywords" content="GRE-Site">
<meta name="author" content="Friedrich Jie Yan">
<link rel="stylesheet" href="style.css" />
<script src="js/cufon-yui.js" type="text/javascript"></script>
		<script src="js/Pirulen_400.font.js" type="text/javascript"></script>
		<script type="text/javascript">
			Cufon.replace('h1'); // Works without a selector engine
			Cufon.replace('#sub1'); // Requires a selector engine for IE 6-7, see above
		</script>

</head>
<body>
<br />
<br />
<div id="page">
  <div id="logo">
	<div id="logoleft">
	<h1 align="left">Graph Runtime Engine</h1>
    <h4 align="left">	 fuels emerging large-scale distributed graph-parallel computing </h4>
	</div>
  </div>
      <!-- menu start -->
<ul id="nav">
	<li class="current"><a href="#">Overview</a></li>
    
	<li><a href="about.html">Abstractions</a></li>
   	<li><a href="examples.html">Examples</a>
    	<ul>
			<li><a href="pagerank.html">PageRank</a></li>
			<li><a href="sssp.html">Single Source Shortest Path</a></li>
           <li><a href="cc.html">Connected Components</a></li>
       </ul>
    </li>
    <li><a href="publication.html">Publication</a></li>
    <li><a href="download.html">Download</a></li>
	<li><a href="contact.html">Contact</a></li>
</ul>
<br>
<br>
       <!-- menu end -->
  <div id="content">
  <h2>What's GRE? </h2>
  <div id="textarea">
  <p></p>
  <p><strong>GRE </strong>(<strong>G</strong>raph<strong> R</strong>untime<strong> E</strong>ngine) is a distributed graph-parallel computing platform written in C++. It is designed for processing emerging graphs with billions of vertices and edges on today's cluster systems. Compared to counterpart systems, GRE shows considerable performance advantage in our experiments, e.g. 2.5∼17 times better  on 8∼16 machines (192 cores) than PowerGraph.</p> 

<h3></h3>
<h3>An Overview of <strong>GRE</strong></h3>
<p></p>
  <figure align="center">
	<img src="images/GRE-Arch.png" width="300" height="273"  alt=""/><br />
  <figcaption>GRE Architecture</figcaption>
</figure>
<p></p>
<p><strong>GRE</strong> proposes<a href="about.html"> Scatter-Combine</a> abstraction to model the graph-parallel computation. <a href="about.html">Scatter-Combine</a> is a data-flow approach based on active message. The active message mechanism can express and efficiently map massive fine-grained edge-level parallelism to underlying cluster systems of hybrid distributed memory and shared memory. </p>
<p>Programming with GRE is very convenient. GRE provides a simple but expressive  API to instantiate <a href="about.html">Scatter-Combine</a> computation and implement graph-parallel algorithms. As an example, one can refer to implementation of <a href="pagerank.html">Page Rank</a>.</p>
<p>Closely coupled Scatter-Combine abstraction, GRE proposes <a href="about.html">Agent-Graph</a> to partition and represent a graph in the distributed form. Agent-Graph has much lower communication needs than either traditional edge-cut partitioning method or GraphLab's vertex-cut model.</p>
<p>To support abstractions of Scatter-Combine and Agent-Graph, GRE implements a high performance runtime system. Currently, GRE runtime provides a BSP execution engine. Its Key features  include:</p>
<ol>
  <li>Column-Oriented Storage of graph properties.</li>
  <li>One-sided active message communication.</li>
  <li>Fine-grained parallelism and data synchronization on multi-core processors.</li>
  </ol>
  
<h3>A technical comparison  of <strong>GRE</strong> and its counterparts</h3>
<p></p>
<p>Besides GRE, there have been several other graph-parallel platforms. As a comparison, we summarize key features of these systems in Table 1.</p>
<p><img src="images/Comparison.png"  alt="html5 blue" width="620" height="100" align="center"></p>
  </div>
  <div id="sidebar">
  <p></p>
  <h3>Graph-parallel Computing</h3>
  <p>Processing large-scale real-world graphs has become increasingly important  in many areas, such as data analytics, web search, and recommendation systems. Their algorithmic kernels are often <strong><em>graph-parallel</em></strong> computation. </p>
  <p>The term graph-parallel has been used in GraphLab related work. Here, <strong><em>graph-parallel</em></strong> computing refers to  graph algorithmic procedures, such as path exploration (e.g. traversal, label propagation) and topology-based iteration (e.g. page rank, clustering), whose execution is data-driven or dictated by the graph structure. Note that not all graph algorithms are graph-parallel. For example, vertex degree calculation and graph transposition are not graph-parallel, and they can be solved better by Map-Reduce model.</p>
  <p>Unfortunately, Distributed graph-parallel computing faces two challenges:
  </p>
  <ol>
    <li><strong>Parallelism expressing.</strong> Due to irregular computation and lack of locality, graph-parallel problems can't fit in well with traditional data-parallel models such as Map-reduce.</li>
    <li><strong>Graph Partitioning.</strong> Since real-world graphs are typically scale-free, their balanced  and low-cut partitioning  are hard or not possible in practice.</li>
  </ol>
  <p>&nbsp;</p>
  <h3>Performance Comparison</h3>
    <p>One iteration of PageRank on Twitter<img src="images/pagerank-runtime.png" width="250" height="78"  alt=""/></p>
  </div>
  <p>&nbsp;</p>
  <div style="clear: both;">&nbsp;</div>
  <img src="images/bg_banner_grey.gif" width="880" height="5" alt="logo_banner" />
  <div id="footer">

 <div id="footerleft">
 ICT,CAS © 2013
 </div>
 
     <div id="footerright"></div>
</div>

</div>
</div>

<br />
<br />



    
</body>
</html>
